#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ°´å°é‡å»ºæ¨¡å—
ç”¨äºä»æ°´å°æ¨¡å‹ä¸­æå–å‚æ•°ï¼Œé‡å»ºè‡ªç¼–ç å™¨å¹¶è¯„ä¼°æ€§èƒ½
"""

import torch
import torch.nn as nn
import numpy as np
import os
from typing import Dict, List, Tuple, Optional
from models.light_autoencoder import LightAutoencoder
from utils.key_matrix_utils import KeyMatrixManager


class WatermarkReconstructor:
    """æ°´å°é‡å»ºå™¨ï¼Œç”¨äºä»æ°´å°æ¨¡å‹ä¸­é‡å»ºè‡ªç¼–ç å™¨"""
    
    def __init__(self, key_matrix_dir: str, autoencoder_weights_dir: str = './save/autoencoder', 
                 args=None, enable_scaling: bool = True, scaling_factor: float = 0.1):
        """
        åˆå§‹åŒ–æ°´å°é‡å»ºå™¨
        
        Args:
            key_matrix_dir: å¯†é’¥çŸ©é˜µç›®å½•
            autoencoder_weights_dir: è‡ªç¼–ç å™¨æƒé‡ç›®å½•
            args: å‚æ•°å¯¹è±¡ï¼ŒåŒ…å«æ°´å°ç¼©æ”¾ç›¸å…³é…ç½®
            enable_scaling: æ˜¯å¦å¯ç”¨æ°´å°å‚æ•°ç¼©æ”¾ï¼ˆå¦‚æœargsä¸ºNoneåˆ™ä½¿ç”¨æ­¤å‚æ•°ï¼‰
            scaling_factor: å›ºå®šç¼©æ”¾å› å­ï¼ˆé»˜è®¤0.1ï¼‰
        """
        self.key_matrix_dir = key_matrix_dir
        self.autoencoder_weights_dir = autoencoder_weights_dir
        self.key_manager = KeyMatrixManager(key_matrix_dir, args, enable_scaling, scaling_factor)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½åŸå§‹è‡ªç¼–ç å™¨ä½œä¸ºå‚è€ƒ
        self.original_autoencoder = self._load_original_autoencoder()
        
        # Î”PCCç›¸å…³å‚æ•°
        self.perf_before = None  # åŸºå‡†æ€§èƒ½ (perf_before)
        self.perf_fail = None    # å¤±æ•ˆæ€§èƒ½ (perf_fail)
        self.tau = None          # é˜ˆå€¼ Ï„ = loss_fail - loss_before
        self.ds_loader = None    # ä¸“ç”¨æ•°æ®é›†åŠ è½½å™¨
        
    def _load_original_autoencoder(self) -> LightAutoencoder:
        """åŠ è½½åŸå§‹è‡ªç¼–ç å™¨ä½œä¸ºæ€§èƒ½å‚è€ƒ"""
        autoencoder = LightAutoencoder().to(self.device)
        
        autoencoder_path = os.path.join(self.autoencoder_weights_dir, 'autoencoder.pth')
        if os.path.exists(autoencoder_path):
            autoencoder.load_state_dict(torch.load(autoencoder_path, map_location=self.device, weights_only=False))
            print(f"âœ“ å·²åŠ è½½åŸå§‹è‡ªç¼–ç å™¨æƒé‡: {autoencoder_path}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°åŸå§‹è‡ªç¼–ç å™¨æƒé‡: {autoencoder_path}")
        
        return autoencoder
    
    def extract_watermark_parameters(self, model_state_dict: Dict[str, torch.Tensor], 
                                   client_id: int, check_pruning: bool = False) -> torch.Tensor:
        """ä»æ¨¡å‹çŠ¶æ€å­—å…¸ä¸­æå–æ°´å°å‚æ•°"""
        try:
            return self.key_manager.extract_watermark(model_state_dict, client_id, check_pruning)
        except Exception as e:
            print(f"âŒ æå–å®¢æˆ·ç«¯ {client_id} çš„æ°´å°å‚æ•°å¤±è´¥: {e}")
            return torch.tensor([])
    
    def reconstruct_autoencoder_from_watermark(self, model_state_dict: Dict[str, torch.Tensor], 
                                             client_id: int) -> LightAutoencoder:
        """ä»æ°´å°å‚æ•°é‡å»ºè‡ªç¼–ç å™¨"""
        watermark_values = self.extract_watermark_parameters(model_state_dict, client_id)
        
        if len(watermark_values) == 0:
            print(f"âŒ æ— æ³•ä»å®¢æˆ·ç«¯ {client_id} æå–æ°´å°å‚æ•°")
            return None
        
        reconstructed_autoencoder = LightAutoencoder().to(self.device)
        
        # åŠ è½½è§£ç å™¨æƒé‡
        decoder_path = os.path.join(self.autoencoder_weights_dir, 'decoder.pth')
        if os.path.exists(decoder_path):
            reconstructed_autoencoder.decoder.load_state_dict(
                torch.load(decoder_path, map_location=self.device, weights_only=False)
            )
            print(f"âœ“ å·²åŠ è½½è§£ç å™¨æƒé‡: {decoder_path}")
        
        # é‡å»ºç¼–ç å™¨å‚æ•°
        self._reconstruct_encoder_from_watermark(reconstructed_autoencoder.encoder, watermark_values)
        
        return reconstructed_autoencoder
    
    def reconstruct_autoencoder_from_all_clients(self, model_state_dict: Dict[str, torch.Tensor]) -> LightAutoencoder:
        """
        ä»æ‰€æœ‰å®¢æˆ·ç«¯çš„æ°´å°å‚æ•°é‡å»ºè‡ªç¼–ç å™¨ï¼ˆç”¨äºä¾µæƒåˆ¤æ–­ï¼‰
        
        Args:
            model_state_dict: æ¨¡å‹çŠ¶æ€å­—å…¸
            
        Returns:
            é‡å»ºçš„è‡ªç¼–ç å™¨
        """
        # è·å–æ‰€æœ‰å®¢æˆ·ç«¯ID
        all_client_ids = self.key_manager.list_clients()
        
        # ä»æ‰€æœ‰å®¢æˆ·ç«¯æå–æ°´å°å‚æ•°
        all_watermark_values = []
        successful_clients = []
        
        for client_id in all_client_ids:
            try:
                watermark_values = self.extract_watermark_parameters(model_state_dict, client_id)
                if len(watermark_values) > 0:
                    all_watermark_values.append(watermark_values)
                    successful_clients.append(client_id)
            except Exception as e:
                pass  # é™é»˜å¤„ç†é”™è¯¯
        
        if not all_watermark_values:
            print("âŒ æœªèƒ½ä»ä»»ä½•å®¢æˆ·ç«¯æå–åˆ°æ°´å°å‚æ•°")
            return None
        
        # åˆå¹¶æ‰€æœ‰æ°´å°å‚æ•°
        combined_watermark_values = torch.cat(all_watermark_values)
        
        # æ£€æŸ¥å‚æ•°æ•°é‡æ˜¯å¦åŒ¹é…ç¼–ç å™¨
        encoder_params = list(LightAutoencoder().encoder.parameters())
        total_encoder_params = sum(param.numel() for param in encoder_params)
        
        if len(combined_watermark_values) != total_encoder_params:
            if len(combined_watermark_values) > total_encoder_params:
                # æˆªæ–­å¤šä½™çš„å‚æ•°
                combined_watermark_values = combined_watermark_values[:total_encoder_params]
            else:
                # å¡«å……ä¸è¶³çš„å‚æ•°
                padding = torch.zeros(total_encoder_params - len(combined_watermark_values))
                combined_watermark_values = torch.cat([combined_watermark_values, padding])
        
        # åˆ›å»ºæ–°çš„è‡ªç¼–ç å™¨
        reconstructed_autoencoder = LightAutoencoder().to(self.device)
        
        # åŠ è½½è§£ç å™¨æƒé‡ï¼ˆä¿æŒä¸å˜ï¼‰
        decoder_path = os.path.join(self.autoencoder_weights_dir, 'decoder.pth')
        if os.path.exists(decoder_path):
            reconstructed_autoencoder.decoder.load_state_dict(
                torch.load(decoder_path, map_location=self.device, weights_only=False)
            )
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°è§£ç å™¨æƒé‡: {decoder_path}")
        
        # é‡å»ºç¼–ç å™¨å‚æ•°
        self._reconstruct_encoder_from_watermark(reconstructed_autoencoder.encoder, combined_watermark_values)
        
        return reconstructed_autoencoder
    
    def _reconstruct_encoder_from_watermark(self, encoder: nn.Module, watermark_values: torch.Tensor):
        """
        ä»æ°´å°å€¼é‡å»ºç¼–ç å™¨å‚æ•°
        
        Args:
            encoder: ç¼–ç å™¨æ¨¡å—
            watermark_values: æ°´å°å€¼
        """
        # ç¡®ä¿æ°´å°å€¼åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        device = next(encoder.parameters()).device
        watermark_values = watermark_values.to(device)
        
        # è·å–ç¼–ç å™¨å‚æ•°ä¿¡æ¯
        encoder_params = list(encoder.parameters())
        total_params = sum(param.numel() for param in encoder_params)
        
        # ç¡®ä¿æ°´å°å‚æ•°æ•°é‡ä¸ç¼–ç å™¨å‚æ•°æ•°é‡åŒ¹é…
        if len(watermark_values) != total_params:
            if len(watermark_values) > total_params:
                watermark_values = watermark_values[:total_params]
            else:
                padding = torch.zeros(total_params - len(watermark_values), device=device)
                watermark_values = torch.cat([watermark_values, padding])
        
        # å°†æ°´å°å€¼åˆ†é…ç»™ç¼–ç å™¨å‚æ•°
        watermark_idx = 0
        for param in encoder_params:
            param_size = param.numel()
            param_values = watermark_values[watermark_idx:watermark_idx + param_size]
            
            # é‡å¡‘å‚æ•°å½¢çŠ¶å¹¶ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            param.data = param_values.reshape(param.shape).to(device)
            watermark_idx += param_size
    
    def evaluate_autoencoder_performance(self, autoencoder: LightAutoencoder, 
                                       test_loader) -> Dict[str, float]:
        """
        è¯„ä¼°è‡ªç¼–ç å™¨æ€§èƒ½
        
        Args:
            autoencoder: è‡ªç¼–ç å™¨æ¨¡å‹
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            
        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        autoencoder.eval()
        total_loss = 0.0
        total_samples = 0
        
        criterion = nn.MSELoss()
        
        with torch.no_grad():
            for data, _ in test_loader:
                data = data.to(self.device)
                
                # é‡å»ºå›¾åƒ
                reconstructed = autoencoder(data)
                
                # è®¡ç®—é‡å»ºæŸå¤±
                loss = criterion(reconstructed, data)
                total_loss += loss.item() * data.size(0)
                total_samples += data.size(0)
        
        # è®¡ç®—å¹³å‡é‡å»ºæŸå¤±
        avg_loss = total_loss / total_samples
        
        # è®¡ç®—é‡å»ºè´¨é‡æŒ‡æ ‡
        reconstruction_quality = self._calculate_reconstruction_quality(autoencoder, test_loader)
        
        return {
            'reconstruction_loss': avg_loss,
            'psnr': reconstruction_quality['psnr'],
            'ssim': reconstruction_quality['ssim'],
            'mse': avg_loss
        }
    
    def evaluate_classification_performance(self, model, test_loader) -> Dict[str, float]:
        """
        è¯„ä¼°æ¨¡å‹åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼ˆé€‚ç”¨äºChestMNISTä»»åŠ¡ï¼‰
        
        Args:
            model: åˆ†ç±»æ¨¡å‹ï¼ˆå¦‚ResNet18ï¼‰
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆChestMNISTï¼‰
            
        Returns:
            åˆ†ç±»æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        model.eval()
        all_predictions = []
        all_targets = []
        
        with torch.no_grad():
            for data, target in test_loader:
                data = data.to(self.device)
                target = target.to(self.device)
                
                # è·å–æ¨¡å‹é¢„æµ‹
                output = model(data)
                
                # ä½¿ç”¨sigmoidæ¿€æ´»
                if len(target.shape) == 2 and target.shape[1] > 1:
                    pred_prob = torch.sigmoid(output)
                else:
                    pred_prob = torch.softmax(output, dim=1)
                
                all_predictions.append(pred_prob.cpu().numpy())
                all_targets.append(target.cpu().numpy())
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹å’Œç›®æ ‡
        all_predictions = np.concatenate(all_predictions, axis=0)
        all_targets = np.concatenate(all_targets, axis=0)
        
        # è®¡ç®—AUC
        try:
            from sklearn.metrics import roc_auc_score
            if len(all_targets.shape) == 2 and all_targets.shape[1] > 1:
                # è®¡ç®—æ¯ä¸ªæ ‡ç­¾çš„AUCï¼Œç„¶åå–å¹³å‡
                auc_scores = []
                for i in range(all_targets.shape[1]):
                    if len(np.unique(all_targets[:, i])) > 1:  # ç¡®ä¿æ ‡ç­¾æœ‰å˜åŒ–
                        auc = roc_auc_score(all_targets[:, i], all_predictions[:, i])
                        auc_scores.append(auc)
                mean_auc = np.mean(auc_scores) if auc_scores else 0.0
            else:
                # ä½¿ç”¨one-vs-restç­–ç•¥
                mean_auc = roc_auc_score(all_targets, all_predictions, multi_class='ovr')
        except ImportError:
            print("è­¦å‘Š: sklearnæœªå®‰è£…ï¼Œæ— æ³•è®¡ç®—AUCï¼Œä½¿ç”¨å‡†ç¡®ç‡ä»£æ›¿")
            # ä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºæ›¿ä»£æŒ‡æ ‡
            if len(all_targets.shape) == 2 and all_targets.shape[1] > 1:
                # ä½¿ç”¨é˜ˆå€¼0.5è¿›è¡ŒäºŒå€¼åŒ–
                pred_binary = (all_predictions > 0.5).astype(int)
                mean_auc = np.mean((pred_binary == all_targets).astype(float))
            else:
                # ä½¿ç”¨argmax
                pred_labels = np.argmax(all_predictions, axis=1)
                mean_auc = np.mean((pred_labels == all_targets).astype(float))
        
        return {
            'auc': mean_auc,
            'predictions': all_predictions,
            'targets': all_targets
        }
    
    def comprehensive_evaluation(self, model_state_dict: Dict[str, torch.Tensor], 
                               client_id: int, 
                               mnist_test_loader,
                               chestmnist_test_loader = None) -> Dict[str, any]:
        """
        ç»¼åˆè¯„ä¼°ï¼šæ°´å°é‡å»ºè´¨é‡ + ä¸»ä»»åŠ¡åˆ†ç±»æ€§èƒ½
        
        Args:
            model_state_dict: æ°´å°æ¨¡å‹çŠ¶æ€å­—å…¸
            client_id: å®¢æˆ·ç«¯ID
            mnist_test_loader: MNISTæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºè‡ªç¼–ç å™¨è¯„ä¼°ï¼‰
            chestmnist_test_loader: ChestMNISTæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºä¸»ä»»åŠ¡è¯„ä¼°ï¼Œå¯é€‰ï¼‰
            
        Returns:
            ç»¼åˆè¯„ä¼°ç»“æœ
        """
        results = {
            'client_id': client_id,
            'watermark_reconstruction': None,
            'classification_performance': None,
            'infringement_assessment': None
        }
        
        # 1. æ°´å°é‡å»ºè¯„ä¼°ï¼ˆåœ¨MNISTä¸Šï¼‰
        print(f"ğŸ” è¯„ä¼°å®¢æˆ·ç«¯ {client_id} çš„æ°´å°é‡å»ºè´¨é‡...")
        reconstructed_autoencoder = self.reconstruct_autoencoder_from_watermark(model_state_dict, client_id)
        
        if reconstructed_autoencoder is not None:
            # è¯„ä¼°é‡å»ºçš„è‡ªç¼–ç å™¨æ€§èƒ½
            reconstruction_metrics = self.evaluate_autoencoder_performance(reconstructed_autoencoder, mnist_test_loader)
            
            # ä¸åŸå§‹è‡ªç¼–ç å™¨æ¯”è¾ƒ
            original_metrics = self.evaluate_autoencoder_performance(self.original_autoencoder, mnist_test_loader)
            comparison_results = self.compare_autoencoder_performance(original_metrics, reconstruction_metrics)
            
            # ä¾µæƒåˆ¤æ–­
            infringement_results = self.assess_infringement(comparison_results)
            
            results['watermark_reconstruction'] = {
                'reconstructed_metrics': reconstruction_metrics,
                'original_metrics': original_metrics,
                'comparison': comparison_results,
                'infringement': infringement_results
            }
            
            print(f"âœ… æ°´å°é‡å»ºè¯„ä¼°å®Œæˆ")
            print(f"   PSNRä¿æŒç‡: {comparison_results['retention']['psnr_retention']:.3f}")
            print(f"   SSIMä¿æŒç‡: {comparison_results['retention']['ssim_retention']:.3f}")
            print(f"   ä¾µæƒåˆ¤æ–­: {'æ˜¯' if infringement_results['overall_infringement'] else 'å¦'}")
        else:
            print(f"âŒ å®¢æˆ·ç«¯ {client_id} æ°´å°é‡å»ºå¤±è´¥")
            results['watermark_reconstruction'] = None
        
        # 2. ä¸»ä»»åŠ¡åˆ†ç±»æ€§èƒ½è¯„ä¼°ï¼ˆåœ¨ChestMNISTä¸Šï¼Œå¦‚æœæä¾›äº†æ•°æ®ï¼‰
        if chestmnist_test_loader is not None:
            print(f"ğŸ” è¯„ä¼°å®¢æˆ·ç«¯ {client_id} çš„ä¸»ä»»åŠ¡åˆ†ç±»æ€§èƒ½...")
            
            # åˆ›å»ºä¸»ä»»åŠ¡æ¨¡å‹ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
            from models.resnet import resnet18
            main_task_model = resnet18(num_classes=7).to(self.device)  # ChestMNISTæœ‰7ä¸ªç±»åˆ«
            
            # åŠ è½½æ¨¡å‹æƒé‡ï¼ˆè¿™é‡Œå‡è®¾model_state_dictå°±æ˜¯ä¸»ä»»åŠ¡æ¨¡å‹çš„æƒé‡ï¼‰
            main_task_model.load_state_dict(model_state_dict)
            
            # è¯„ä¼°åˆ†ç±»æ€§èƒ½
            classification_metrics = self.evaluate_classification_performance(main_task_model, chestmnist_test_loader)
            
            results['classification_performance'] = classification_metrics
            
            print(f"âœ… ä¸»ä»»åŠ¡åˆ†ç±»æ€§èƒ½è¯„ä¼°å®Œæˆ")
            print(f"   AUC: {classification_metrics['auc']:.3f}")
        else:
            print("â„¹ï¸  æœªæä¾›ChestMNISTæµ‹è¯•æ•°æ®ï¼Œè·³è¿‡ä¸»ä»»åŠ¡æ€§èƒ½è¯„ä¼°")
        
        return results
    
    def _calculate_reconstruction_quality(self, autoencoder: LightAutoencoder, 
                                        test_loader) -> Dict[str, float]:
        """
        è®¡ç®—é‡å»ºè´¨é‡æŒ‡æ ‡ï¼ˆPSNR, SSIMç­‰ï¼‰
        
        Args:
            autoencoder: è‡ªç¼–ç å™¨æ¨¡å‹
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            
        Returns:
            è´¨é‡æŒ‡æ ‡å­—å…¸
        """
        autoencoder.eval()
        
        # è·å–ä¸€å°æ‰¹æ•°æ®è¿›è¡Œè´¨é‡è¯„ä¼°
        data, _ = next(iter(test_loader))
        data = data.to(self.device)
        
        with torch.no_grad():
            reconstructed = autoencoder(data)
            
            # è®¡ç®—PSNR
            mse = torch.mean((data - reconstructed) ** 2)
            if mse > 0:
                psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
            else:
                psnr = torch.tensor(float('inf'))
            
            # è®¡ç®—SSIMï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            ssim = self._calculate_ssim(data, reconstructed)
        
        return {
            'psnr': psnr.item(),
            'ssim': ssim
        }
    
    def _calculate_ssim(self, x: torch.Tensor, y: torch.Tensor) -> float:
        """
        è®¡ç®—SSIMï¼ˆç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼‰
        
        Args:
            x: åŸå§‹å›¾åƒ
            y: é‡å»ºå›¾åƒ
            
        Returns:
            SSIMå€¼
        """
        # ç®€åŒ–çš„SSIMè®¡ç®—
        mu_x = torch.mean(x)
        mu_y = torch.mean(y)
        
        sigma_x = torch.var(x)
        sigma_y = torch.var(y)
        sigma_xy = torch.mean((x - mu_x) * (y - mu_y))
        
        c1 = 0.01 ** 2
        c2 = 0.03 ** 2
        
        ssim = ((2 * mu_x * mu_y + c1) * (2 * sigma_xy + c2)) / \
               ((mu_x ** 2 + mu_y ** 2 + c1) * (sigma_x + sigma_y + c2))
        
        return ssim.item()
    
    def compare_with_original_autoencoder(self, reconstructed_autoencoder: LightAutoencoder, 
                                        test_loader) -> Dict[str, float]:
        """
        å°†é‡å»ºçš„è‡ªç¼–ç å™¨ä¸åŸå§‹è‡ªç¼–ç å™¨è¿›è¡Œæ¯”è¾ƒ
        
        Args:
            reconstructed_autoencoder: é‡å»ºçš„è‡ªç¼–ç å™¨
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            
        Returns:
            æ¯”è¾ƒç»“æœå­—å…¸
        """
        # è¯„ä¼°é‡å»ºçš„è‡ªç¼–ç å™¨
        reconstructed_metrics = self.evaluate_autoencoder_performance(
            reconstructed_autoencoder, test_loader
        )
        
        # è¯„ä¼°åŸå§‹è‡ªç¼–ç å™¨
        original_metrics = self.evaluate_autoencoder_performance(
            self.original_autoencoder, test_loader
        )
        
        # è®¡ç®—æ€§èƒ½å·®å¼‚
        performance_diff = {
            'reconstruction_loss_diff': reconstructed_metrics['reconstruction_loss'] - original_metrics['reconstruction_loss'],
            'psnr_diff': reconstructed_metrics['psnr'] - original_metrics['psnr'],
            'ssim_diff': reconstructed_metrics['ssim'] - original_metrics['ssim'],
            'mse_diff': reconstructed_metrics['mse'] - original_metrics['mse']
        }
        
        # è®¡ç®—æ€§èƒ½ä¿æŒç‡
        performance_retention = {
            'psnr_retention': reconstructed_metrics['psnr'] / original_metrics['psnr'] if original_metrics['psnr'] > 0 else 0,
            'ssim_retention': reconstructed_metrics['ssim'] / original_metrics['ssim'] if original_metrics['ssim'] > 0 else 0
        }
        
        return {
            'reconstructed': reconstructed_metrics,
            'original': original_metrics,
            'difference': performance_diff,
            'retention': performance_retention
        }
    
    def assess_infringement(self, comparison_results: Dict[str, float], 
                          thresholds: Dict[str, float] = None) -> Dict[str, bool]:
        """
        åŸºäºè‡ªç¼–ç å™¨æ€§èƒ½è¯„ä¼°æ˜¯å¦æ„æˆä¾µæƒ
        
        Args:
            comparison_results: æ¯”è¾ƒç»“æœ
            thresholds: ä¾µæƒåˆ¤æ–­é˜ˆå€¼
            
        Returns:
            ä¾µæƒåˆ¤æ–­ç»“æœ
        """
        if thresholds is None:
            # é»˜è®¤é˜ˆå€¼
            thresholds = {
                'psnr_retention_min': 0.7,  # PSNRä¿æŒç‡è‡³å°‘70%
                'ssim_retention_min': 0.7,  # SSIMä¿æŒç‡è‡³å°‘70%
                'reconstruction_loss_max_ratio': 2.0,  # é‡å»ºæŸå¤±ä¸è¶…è¿‡åŸå§‹æŸå¤±çš„2å€
            }
        
        retention = comparison_results['retention']
        diff = comparison_results['difference']
        original = comparison_results['original']
        
        # ä¾µæƒåˆ¤æ–­æ ‡å‡†
        infringement_criteria = {
            'psnr_retention_adequate': retention['psnr_retention'] >= thresholds['psnr_retention_min'],
            'ssim_retention_adequate': retention['ssim_retention'] >= thresholds['ssim_retention_min'],
            'reconstruction_loss_acceptable': (
                diff['reconstruction_loss_diff'] / original['reconstruction_loss'] 
                <= thresholds['reconstruction_loss_max_ratio']
            ),
        }
        
        # ç»¼åˆåˆ¤æ–­
        infringement_criteria['overall_infringement'] = all(infringement_criteria.values())
        
        return infringement_criteria
    
    def setup_deltapcc_evaluation(self, ds_loader, perf_fail_ratio: float = 0.1):
        """
        è®¾ç½®Î”PCCè¯„ä¼°å‚æ•°
        
        Args:
            ds_loader: ä¸“ç”¨æ•°æ®é›†åŠ è½½å™¨ (Ds)
            perf_fail_ratio: å¤±æ•ˆæ€§èƒ½æ¯”ä¾‹ï¼ˆç›¸å¯¹äºåŸºå‡†æ€§èƒ½çš„å€æ•°ï¼‰
        """
        self.ds_loader = ds_loader
        
        # è®¡ç®—åŸºå‡†æ€§èƒ½ perf_before
        print("è®¡ç®—åŸºå‡†æ€§èƒ½ perf_before...")
        self.perf_before = self.evaluate_autoencoder_performance(
            self.original_autoencoder, ds_loader
        )['mse']
        
        # ä½¿ç”¨ç›¸å¯¹é˜ˆå€¼è®¡ç®—æ–¹å¼ï¼ˆä¸å‰ªææ”»å‡»ä¸€è‡´ï¼‰
        self.perf_fail = self.perf_before * (1 + perf_fail_ratio)
        self.tau = self.perf_fail - self.perf_before
        
        print(f"Î”PCCè¯„ä¼°å‚æ•°è®¾ç½®å®Œæˆ:")
        print(f"  åŸºå‡†æ€§èƒ½ (perf_before): {self.perf_before:.6f}")
        print(f"  å¤±æ•ˆæ€§èƒ½ (perf_fail): {self.perf_fail:.6f}")
        print(f"  é˜ˆå€¼ (Ï„): {self.tau:.6f}")
        
        if self.tau <= 0:
            print("âš ï¸  è­¦å‘Š: é˜ˆå€¼Ï„ <= 0ï¼Œè¿™å¯èƒ½å¯¼è‡´Î”PCCè®¡ç®—å¼‚å¸¸")
    
    def evaluate_encoder_decoder_separated(self, model_state_dict: Dict[str, torch.Tensor], 
                                         client_id: int, test_loader) -> Dict[str, float]:
        """
        åˆ†ç¦»è¯„ä¼°ç¼–ç å™¨å’Œè§£ç å™¨ï¼ˆå‚è€ƒä»£ç é£æ ¼ï¼‰
        ç¼–ç å™¨ï¼šä»æ°´å°æ¨¡å‹æå–ï¼ˆå¯èƒ½è¢«æ”»å‡»ï¼‰
        è§£ç å™¨ï¼šå§‹ç»ˆä½¿ç”¨åŸå§‹é¢„è®­ç»ƒæƒé‡
        
        Args:
            model_state_dict: å¾…æµ‹æ¨¡å‹çŠ¶æ€å­—å…¸
            client_id: å®¢æˆ·ç«¯ID
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            
        Returns:
            è¯„ä¼°ç»“æœ
        """
        # æå–æ°´å°å‚æ•°
        watermark_values = self.extract_watermark_parameters(model_state_dict, client_id)
        
        if len(watermark_values) == 0:
            return {
                'mse': float('inf'),
                'ssim': 0.0,
                'psnr': 0.0,
                'reconstruction_success': False,
                'watermark_damaged': False
            }
        
        # åˆ›å»ºæ–°çš„è‡ªç¼–ç å™¨
        autoencoder = LightAutoencoder().to(self.device)
        
        # åŠ è½½åŸå§‹è§£ç å™¨æƒé‡ï¼ˆå§‹ç»ˆä¸å˜ï¼‰
        decoder_path = os.path.join(self.autoencoder_weights_dir, 'decoder.pth')
        if os.path.exists(decoder_path):
            autoencoder.decoder.load_state_dict(
                torch.load(decoder_path, map_location=self.device, weights_only=False)
            )
        else:
            print(f"âŒ è§£ç å™¨æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {decoder_path}")
            return {
                'mse': float('inf'),
                'ssim': 0.0,
                'psnr': 0.0,
                'reconstruction_success': False,
                'watermark_damaged': False
            }
        
        # é‡å»ºç¼–ç å™¨å‚æ•°ï¼ˆä»æ°´å°æ¨¡å‹æå–ï¼‰
        self._reconstruct_encoder_from_watermark(autoencoder.encoder, watermark_values)
        
        # è¯„ä¼°æ€§èƒ½
        metrics = self.evaluate_autoencoder_performance(autoencoder, test_loader)
        
        return {
            'mse': metrics['mse'],
            'ssim': metrics['ssim'],
            'psnr': metrics['psnr'],
            'reconstruction_success': True,
            'watermark_damaged': False
        }

    def calculate_deltapcc(self, model_state_dict: Dict[str, torch.Tensor], 
                          client_id: int, check_pruning: bool = True) -> Dict[str, float]:
        """
        è®¡ç®—Î”PCCå€¼
        
        Args:
            model_state_dict: å¾…æµ‹æ¨¡å‹çŠ¶æ€å­—å…¸
            client_id: å®¢æˆ·ç«¯ID
            check_pruning: æ˜¯å¦æ£€æŸ¥å‰ªæå¯¹æ°´å°çš„å½±å“
            
        Returns:
            Î”PCCè®¡ç®—ç»“æœ
        """
        if self.ds_loader is None or self.tau is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨ setup_deltapcc_evaluation() è®¾ç½®è¯„ä¼°å‚æ•°")
        
        # æ£€æŸ¥æ°´å°æ˜¯å¦è¢«å‰ªæç ´å
        watermark_values = self.extract_watermark_parameters(model_state_dict, client_id, check_pruning)
        
        # å¦‚æœå¯ç”¨äº†å‰ªææ£€æŸ¥ï¼Œæ£€æµ‹æ°´å°å®Œæ•´æ€§
        watermark_damaged = False
        if check_pruning and len(watermark_values) > 0:
            # æ£€æŸ¥æ°´å°å€¼æ˜¯å¦å®Œå…¨ç­‰äº0ï¼ˆè¢«å‰ªæï¼‰
            damaged_count = (watermark_values == 0.0).sum().item()
            total_watermark_count = len(watermark_values)
            watermark_damaged = damaged_count > 0
            
            if watermark_damaged:
                print(f"âš ï¸  æ£€æµ‹åˆ°æ°´å°è¢«å‰ªæç ´å: {damaged_count}/{total_watermark_count} ä¸ªæ°´å°ä½ç½®è¢«å‰ªæ‰")
                # æ³¨æ„ï¼šæ°´å°ç ´åä¿¡æ¯ä»…ç”¨äºè®°å½•ï¼Œä¸å½±å“ä¾µæƒåˆ¤æ–­
                # ä¾µæƒåˆ¤æ–­å°†å®Œå…¨åŸºäºPCCå€¼
        
        # ä»å¾…æµ‹æ¨¡å‹é‡å»ºè‡ªç¼–ç å™¨
        reconstructed_autoencoder = self.reconstruct_autoencoder_from_watermark(
            model_state_dict, client_id
        )
        
        if reconstructed_autoencoder is None:
            return {
                'delta_pcc': float('inf'),
                'perf_after': float('inf'),
                'delta_perf': float('inf'),
                'infringement_detected': False,
                'reconstruction_success': False,
                'watermark_damaged': watermark_damaged
            }
        
        # åœ¨ä¸“ç”¨æ•°æ®é›†ä¸Šæµ‹è¯•é‡å»ºåçš„æ€§èƒ½
        perf_after_metrics = self.evaluate_autoencoder_performance(
            reconstructed_autoencoder, self.ds_loader
        )
        perf_after = perf_after_metrics['mse']
        
        # è®¡ç®—æ€§èƒ½å˜åŒ– Î”perf = |perf_after - perf_before|
        delta_perf = abs(perf_after - self.perf_before)
        
        # è®¡ç®—Î”PCC = Î”perf / Ï„
        delta_pcc = delta_perf / self.tau if self.tau > 0 else float('inf')
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"  è°ƒè¯•ä¿¡æ¯: perf_before={self.perf_before:.6f}, perf_after={perf_after:.6f}")
        print(f"  è°ƒè¯•ä¿¡æ¯: perf_fail={self.perf_fail:.6f}, tau={self.tau:.6f}")
        print(f"  è°ƒè¯•ä¿¡æ¯: delta_perf={delta_perf:.6f}, delta_pcc={delta_pcc:.6f}")
        
        # ä¾µæƒåˆ¤æ–­: åªåŸºäºÎ”PCC < 1 è¡¨ç¤ºä¾µæƒ
        infringement_detected = delta_pcc < 1.0
        
        return {
            'delta_pcc': delta_pcc,
            'perf_before': self.perf_before,
            'perf_after': perf_after,
            'perf_fail': self.perf_fail,
            'delta_perf': delta_perf,
            'tau': self.tau,
            'infringement_detected': infringement_detected,
            'reconstruction_success': True,
            'watermark_damaged': watermark_damaged,
            'damaged_ratio': damaged_count / total_watermark_count if watermark_damaged else 0.0,
            'psnr': perf_after_metrics['psnr'],
            'ssim': perf_after_metrics['ssim']
        }
    
    def batch_evaluate_deltapcc(self, model_state_dicts: List[Dict[str, torch.Tensor]], 
                               client_ids: List[int]) -> Dict[str, List[float]]:
        """
        æ‰¹é‡è¯„ä¼°å¤šä¸ªæ¨¡å‹çš„Î”PCC
        
        Args:
            model_state_dicts: æ¨¡å‹çŠ¶æ€å­—å…¸åˆ—è¡¨
            client_ids: å®¢æˆ·ç«¯IDåˆ—è¡¨
            
        Returns:
            æ‰¹é‡è¯„ä¼°ç»“æœ
        """
        if self.ds_loader is None or self.tau is None:
            raise ValueError("è¯·å…ˆè°ƒç”¨ setup_deltapcc_evaluation() è®¾ç½®è¯„ä¼°å‚æ•°")
        
        results = {
            'delta_pcc': [],
            'perf_before': [],
            'perf_after': [],
            'perf_fail': [],
            'delta_perf': [],
            'tau': [],
            'infringement_detected': [],
            'reconstruction_success': [],
            'psnr': [],
            'ssim': []
        }
        
        print(f"æ‰¹é‡è¯„ä¼° {len(model_state_dicts)} ä¸ªæ¨¡å‹çš„Î”PCC...")
        
        for i, (model_state_dict, client_id) in enumerate(zip(model_state_dicts, client_ids)):
            print(f"è¯„ä¼°æ¨¡å‹ {i+1}/{len(model_state_dicts)} (å®¢æˆ·ç«¯ {client_id})...")
            
            try:
                result = self.calculate_deltapcc(model_state_dict, client_id)
                
                for key, value in result.items():
                    results[key].append(value)
                    
            except Exception as e:
                print(f"âŒ æ¨¡å‹ {i+1} è¯„ä¼°å¤±è´¥: {e}")
                # æ·»åŠ å¤±è´¥ç»“æœ
                for key in results.keys():
                    if key == 'infringement_detected' or key == 'reconstruction_success':
                        results[key].append(False)
                    else:
                        results[key].append(float('inf'))
        
        return results
    
    def analyze_deltapcc_results(self, results: Dict[str, List[float]]) -> Dict[str, float]:
        """
        åˆ†æÎ”PCCè¯„ä¼°ç»“æœ
        
        Args:
            results: æ‰¹é‡è¯„ä¼°ç»“æœ
            
        Returns:
            åˆ†æç»“æœç»Ÿè®¡
        """
        delta_pcc_values = [v for v in results['delta_pcc'] if v != float('inf')]
        infringement_detected = results['infringement_detected']
        reconstruction_success = results['reconstruction_success']
        
        if not delta_pcc_values:
            return {
                'total_models': len(results['delta_pcc']),
                'successful_reconstructions': 0,
                'infringement_rate': 0.0,
                'avg_delta_pcc': float('inf'),
                'min_delta_pcc': float('inf'),
                'max_delta_pcc': float('inf'),
                'std_delta_pcc': float('inf')
            }
        
        successful_reconstructions = sum(reconstruction_success)
        infringement_count = sum(infringement_detected)
        
        return {
            'total_models': len(results['delta_pcc']),
            'successful_reconstructions': successful_reconstructions,
            'reconstruction_success_rate': successful_reconstructions / len(results['delta_pcc']),
            'infringement_count': infringement_count,
            'infringement_rate': infringement_count / successful_reconstructions if successful_reconstructions > 0 else 0.0,
            'avg_delta_pcc': np.mean(delta_pcc_values),
            'min_delta_pcc': np.min(delta_pcc_values),
            'max_delta_pcc': np.max(delta_pcc_values),
            'std_delta_pcc': np.std(delta_pcc_values),
            'median_delta_pcc': np.median(delta_pcc_values)
        }


def create_test_loader_for_autoencoder(batch_size: int = 128, num_samples: int = 1000):
    """
    ä¸ºè‡ªç¼–ç å™¨åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
    
    Args:
        batch_size: æ‰¹å¤§å°
        num_samples: æ ·æœ¬æ•°é‡
        
    Returns:
        æµ‹è¯•æ•°æ®åŠ è½½å™¨
    """
    from torchvision import datasets, transforms
    from torch.utils.data import DataLoader, Subset
    
    # ä½¿ç”¨MNISTæ•°æ®é›†ä½œä¸ºè‡ªç¼–ç å™¨çš„æµ‹è¯•æ•°æ®
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])
    
    # åŠ è½½MNISTæµ‹è¯•é›†
    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)
    
    # é™åˆ¶æ ·æœ¬æ•°é‡
    if num_samples < len(test_dataset):
        indices = torch.randperm(len(test_dataset))[:num_samples]
        test_dataset = Subset(test_dataset, indices)
    
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    return test_loader


def test_watermark_reconstruction():
    """æµ‹è¯•æ°´å°é‡å»ºåŠŸèƒ½"""
    print("æµ‹è¯•æ°´å°é‡å»ºåŠŸèƒ½...")
    
    # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
    key_matrix_dir = './save/key_matrix/resnet/client10'  # é»˜è®¤è·¯å¾„
    autoencoder_weights_dir = './save/autoencoder'
    
    if not os.path.exists(key_matrix_dir):
        print(f"âŒ å¯†é’¥çŸ©é˜µç›®å½•ä¸å­˜åœ¨: {key_matrix_dir}")
        return
    
    if not os.path.exists(autoencoder_weights_dir):
        print(f"âŒ è‡ªç¼–ç å™¨æƒé‡ç›®å½•ä¸å­˜åœ¨: {autoencoder_weights_dir}")
        return
    
    # åˆ›å»ºæ°´å°é‡å»ºå™¨
    reconstructor = WatermarkReconstructor(key_matrix_dir, autoencoder_weights_dir)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
    test_loader = create_test_loader_for_autoencoder()
    
    # è®¾ç½®Î”PCCè¯„ä¼°å‚æ•°
    print("è®¾ç½®Î”PCCè¯„ä¼°å‚æ•°...")
    reconstructor.setup_deltapcc_evaluation(test_loader, perf_fail_ratio=0.1)
    
    # æ¨¡æ‹Ÿä¸€ä¸ªæ°´å°æ¨¡å‹ï¼ˆè¿™é‡Œä½¿ç”¨éšæœºå‚æ•°ï¼‰
    print("åˆ›å»ºæ¨¡æ‹Ÿæ°´å°æ¨¡å‹...")
    from models.resnet import resnet18
    model = resnet18(num_classes=14, in_channels=1, input_size=28)
    model_state_dict = model.state_dict()
    
    # æµ‹è¯•Î”PCCè®¡ç®—
    client_id = 0
    print(f"æµ‹è¯•å®¢æˆ·ç«¯ {client_id} çš„Î”PCCè®¡ç®—...")
    
    deltapcc_result = reconstructor.calculate_deltapcc(model_state_dict, client_id)
    
    if deltapcc_result['reconstruction_success']:
        print("âœ“ Î”PCCè®¡ç®—æˆåŠŸ")
        
        # ç®€åŒ–çš„Î”PCCè¯„ä¼°ç»“æœ
        infringement_status = "ä¾µæƒ" if deltapcc_result['infringement_detected'] else "æœªä¾µæƒ"
        print(f"Î”PCC: {deltapcc_result['delta_pcc']:.3f} | ä¾µæƒåˆ¤æ–­: {infringement_status}")
        
    else:
        print("âŒ Î”PCCè®¡ç®—å¤±è´¥")
    
    # æµ‹è¯•ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”
    print("\n=== ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯” ===")
    reconstructed_autoencoder = reconstructor.reconstruct_autoencoder_from_watermark(
        model_state_dict, client_id
    )
    
    if reconstructed_autoencoder is not None:
        comparison_results = reconstructor.compare_with_original_autoencoder(
            reconstructed_autoencoder, test_loader
        )
        
        print(f"é‡å»ºè‡ªç¼–ç å™¨ - PSNR: {comparison_results['reconstructed']['psnr']:.2f}, "
              f"SSIM: {comparison_results['reconstructed']['ssim']:.4f}")
        print(f"åŸå§‹è‡ªç¼–ç å™¨ - PSNR: {comparison_results['original']['psnr']:.2f}, "
              f"SSIM: {comparison_results['original']['ssim']:.4f}")
        
        print(f"\næ€§èƒ½ä¿æŒç‡:")
        print(f"PSNRä¿æŒç‡: {comparison_results['retention']['psnr_retention']:.2%}")
        print(f"SSIMä¿æŒç‡: {comparison_results['retention']['ssim_retention']:.2%}")
        
        # ä¼ ç»Ÿä¾µæƒåˆ¤æ–­
        infringement_results = reconstructor.assess_infringement(comparison_results)
        print(f"\nä¼ ç»Ÿä¾µæƒåˆ¤æ–­: {'ä¾µæƒ' if infringement_results['overall_infringement'] else 'æœªä¾µæƒ'}")
        
    else:
        print("âŒ ä¼ ç»Ÿæ–¹æ³•é‡å»ºå¤±è´¥")


def test_deltapcc_batch_evaluation():
    """æµ‹è¯•Î”PCCæ‰¹é‡è¯„ä¼°åŠŸèƒ½"""
    print("\næµ‹è¯•Î”PCCæ‰¹é‡è¯„ä¼°åŠŸèƒ½...")
    
    # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
    key_matrix_dir = './save/key_matrix/resnet/client10'  # é»˜è®¤è·¯å¾„
    autoencoder_weights_dir = './save/autoencoder'
    
    if not os.path.exists(key_matrix_dir):
        print(f"âŒ å¯†é’¥çŸ©é˜µç›®å½•ä¸å­˜åœ¨: {key_matrix_dir}")
        return
    
    if not os.path.exists(autoencoder_weights_dir):
        print(f"âŒ è‡ªç¼–ç å™¨æƒé‡ç›®å½•ä¸å­˜åœ¨: {autoencoder_weights_dir}")
        return
    
    # åˆ›å»ºæ°´å°é‡å»ºå™¨
    reconstructor = WatermarkReconstructor(key_matrix_dir, autoencoder_weights_dir)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
    test_loader = create_test_loader_for_autoencoder()
    
    # è®¾ç½®Î”PCCè¯„ä¼°å‚æ•°
    reconstructor.setup_deltapcc_evaluation(test_loader, perf_fail_ratio=0.1)
    
    # åˆ›å»ºå¤šä¸ªæ¨¡æ‹Ÿæ¨¡å‹
    print("åˆ›å»ºå¤šä¸ªæ¨¡æ‹Ÿæ°´å°æ¨¡å‹...")
    from models.resnet import resnet18
    model_state_dicts = []
    client_ids = list(range(5))  # æµ‹è¯•5ä¸ªå®¢æˆ·ç«¯
    
    for i in range(5):
        model = resnet18(num_classes=14, in_channels=1, input_size=28)
        model_state_dicts.append(model.state_dict())
    
    # æ‰¹é‡è¯„ä¼°
    results = reconstructor.batch_evaluate_deltapcc(model_state_dicts, client_ids)
    
    # åˆ†æç»“æœ
    analysis = reconstructor.analyze_deltapcc_results(results)
    
    print("\n=== æ‰¹é‡è¯„ä¼°ç»“æœåˆ†æ ===")
    print(f"æ€»æ¨¡å‹æ•°: {analysis['total_models']}")
    print(f"æˆåŠŸé‡å»ºæ•°: {analysis['successful_reconstructions']}")
    print(f"é‡å»ºæˆåŠŸç‡: {analysis['reconstruction_success_rate']:.2%}")
    print(f"ä¾µæƒæ£€æµ‹æ•°: {analysis['infringement_count']}")
    print(f"ä¾µæƒæ£€æµ‹ç‡: {analysis['infringement_rate']:.2%}")
    print(f"å¹³å‡Î”PCC: {analysis['avg_delta_pcc']:.6f}")
    print(f"æœ€å°Î”PCC: {analysis['min_delta_pcc']:.6f}")
    print(f"æœ€å¤§Î”PCC: {analysis['max_delta_pcc']:.6f}")
    print(f"Î”PCCæ ‡å‡†å·®: {analysis['std_delta_pcc']:.6f}")
    print(f"Î”PCCä¸­ä½æ•°: {analysis['median_delta_pcc']:.6f}")


if __name__ == '__main__':
    test_watermark_reconstruction()
    test_deltapcc_batch_evaluation()
